{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Implementing VGG19 paper from scratch in Keras"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Activation, Dropout, Flatten, Dense\n\nimport numpy as np\nnp.random.seed(42)","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (224,224,3)\ninitializer = tf.keras.initializers.GlorotNormal() # the authors of VGG19 paper did not used Glorot Xavier initialization but they mentioned that this can be also used\n\nVGG19 = Sequential([\n    Conv2D(filters = 64, kernel_size=(3,3), padding=\"same\", activation='relu', input_shape=input_shape, kernel_initializer = initializer),\n    Conv2D(filters = 64, kernel_size=(3,3), padding=\"same\", activation='relu', kernel_initializer = initializer),\n    MaxPool2D(pool_size=(2,2), strides=(2,2)),\n    \n    Conv2D(filters = 128, kernel_size=(3,3), padding=\"same\", activation='relu', kernel_initializer = initializer),\n    Conv2D(filters = 128, kernel_size=(3,3), padding=\"same\", activation='relu', kernel_initializer = initializer),\n    MaxPool2D(pool_size=(2,2), strides=(2,2)),\n    \n    Conv2D(filters = 256, kernel_size=(3,3), padding=\"same\", activation='relu'),\n    Conv2D(filters = 256, kernel_size=(3,3), padding=\"same\", activation='relu'),\n    Conv2D(filters = 256, kernel_size=(3,3), padding=\"same\", activation='relu'),\n    Conv2D(filters = 256, kernel_size=(3,3), padding=\"same\", activation='relu'),\n    MaxPool2D(pool_size=(2,2), strides=(2,2)),\n    \n    Conv2D(filters = 512, kernel_size=(3,3), padding=\"same\", activation='relu'),\n    Conv2D(filters = 512, kernel_size=(3,3), padding=\"same\", activation='relu'),\n    Conv2D(filters = 512, kernel_size=(3,3), padding=\"same\", activation='relu'),\n    Conv2D(filters = 512, kernel_size=(3,3), padding=\"same\", activation='relu'),\n    MaxPool2D(pool_size=(2,2), strides=(2,2)),\n    \n    Conv2D(filters = 512, kernel_size=(3,3), padding=\"same\", activation='relu'),\n    Conv2D(filters = 512, kernel_size=(3,3), padding=\"same\", activation='relu'),\n    Conv2D(filters = 512, kernel_size=(3,3), padding=\"same\", activation='relu'),\n    Conv2D(filters = 512, kernel_size=(3,3), padding=\"same\", activation='relu'),\n    MaxPool2D(pool_size=(2,2), strides=(2,2)),\n    \n    Flatten(),\n    Dense(units=4096, activation='relu', kernel_regularizer='l2', kernel_initializer = initializer),\n    Dropout(0.5),\n    Dense(units=4096, activation='relu', kernel_regularizer='l2', kernel_initializer = initializer),\n    Dropout(0.5),\n    Dense(units=1000, activation='softmax', kernel_initializer = initializer)\n\n])\n\nVGG19.summary()","execution_count":2,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 224, 224, 64)      1792      \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 25088)             0         \n_________________________________________________________________\ndense (Dense)                (None, 4096)              102764544 \n_________________________________________________________________\ndropout (Dropout)            (None, 4096)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 4096)              16781312  \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 4096)              0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 1000)              4097000   \n=================================================================\nTotal params: 143,667,240\nTrainable params: 143,667,240\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"VGG19.save(\"../working/VGG19Arch.keras\")","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation"},{"metadata":{},"cell_type":"markdown","source":"##### VGG19 uses random cropping and random horizontal flip for data augmentation\nSince random cropping is not available in ImageDataGenerator, we create our own random crop generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_crop(img, random_crop_size):\n    assert img.shape[2] == 3\n    height, width = img.shape[0], img.shape[1]\n    dy, dx = random_crop_size\n    x = np.random.randint(0, width - dx + 1)\n    y = np.random.randint(0, height - dy + 1)\n    return img[y:(y+dy), x:(x+dx), :]\n\ndef crop_generator(batches, crop_length):\n    while True:\n        batch_x, batch_y = next(batches)\n        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3));\n        for i in range(batch_x.shape[0]):\n            batch_crops = random_crop(batch_x[i], (crop_length, crop_length))\n        yield(batch_crops, batch_y)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\nTRAIN_DIR = \"../input/imagenetmini-1000/imagenet-mini/train/\"\nVAL_DIR = \"../input/imagenetmini-1000/imagenet-mini/val/\"\nbatch_size = 64\n\ntrain_generator = ImageDataGenerator(horizontal_flip = True)\nval_generator = ImageDataGenerator(horizontal_flip = True)\n\ntrain_gen = train_generator.flow_from_directory(TRAIN_DIR, target_size=(256, 256), batch_size=batch_size, class_mode='categorical')\nval_gen = val_generator.flow_from_directory(VAL_DIR, target_size=(256, 256), batch_size=batch_size, class_mode='categorical')\n\ntrain_batches = crop_generator(train_gen, 224)\nval_batches = crop_generator(val_gen, 224)","execution_count":13,"outputs":[{"output_type":"stream","text":"Found 34745 images belonging to 1000 classes.\nFound 3923 images belonging to 1000 classes.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Training the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"VGG19.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 2\n\nhistory = VGG19.fit_generator(train_batches, \n                              epochs = epochs, \n                              steps_per_epoch = 34745 // batch_size, \n                              validation_data = val_batches,\n                              validation_steps = 3923 // batch_size,\n                              verbose = 1)","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch 1/2\n395/542 [====================>.........] - ETA: 2:35 - loss: 29.9660 - accuracy: 0.0026","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}